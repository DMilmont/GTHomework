---
title: "SVM Week 1"
author: "David Milmont"
date: "May 21, 2017"
output: pdf_document
---

##Question 1: A situation at my job where a classification model would be useful is the area of fraud detection. Fraudulent transaction can be classified using predictors such as orderAmount, OrderVelocity, DaysasCustomer, TimeonLogin, FundingMethod.

##Questions 2-3 are answered below

## Loading Packages and Downloading Data - Creating Train, Test, Validate data sets 

```{r loading required libraries and importing data, echo=TRUE}
library('kernlab')
library('RCurl')
library('ggplot2')
library('GGally')
library('mlr')
library('kknn')

file <- getURL('https://d37djvu3ytnwxt.cloudfront.net/assets/courseware/v1/e39a3df780dacd5503df6a8322d72cd2/asset-v1:GTx+ISYE6501x+2T2017+type@asset+block/credit_card_data-headers.txt', ssl.verifyhost=FALSE, ssl.verifypeer=FALSE)

data <- read.csv(textConnection(file), header=T, sep = "\t")

#Summary of data
summarizeColumns(data)

#Create data frame split 
set.seed(546)

#shuffling to ensure randomness
data <- data[sample(nrow(data)),]

#Getting idea of sizes 
nrow(data) * .60
nrow(data) * .20
nrow(data) * .20

#Spliting Manually - KISS method 
train <- data[1:394,]
test <- data[395:525,]
validate <- data[526:654,]

```

## Visualization
Quick visual to see how the data is correlated
```{r, fig.height=10, fig.width=10, message=FALSE, warning=FALSE}

data[,11] <- as.factor(data[,11])
GGally::ggpairs(data[, c(2:4,9:11)], aes(colour=R1))

```



##Question Number 2: Creating the Model - SVM

Selected the polydot kernal as it has the highest accuracy. After runing MLR package for parameter hypertuning settled with C=2.73e+06 for 100% accuracy  - This results in a very small margin hyperplane. I suspect in a real life scenerio this is not optimal as the use case would benefit from some margin of error for review scenerios. 
```{r, echo=TRUE}

#Creating matrix to train model 
x <- as.matrix(data[,1:10])
#creating target 
y <- data[,11]

model <- ksvm(y ~ x, type = "C-svc", kernal = "polydot", C=2.73e+06, scaled = TRUE, cross = 5)

a <- colSums(data[model@SVindex,1:10]*model@coef[[1]])
cat('a:',a,'\n')

a0 <- sum(a*data[1,1:10]) - model@b
cat('a0:',a0,'\n')

pred <- predict(model,data[,1:10])
# pred
data$prediction <- pred

cat('SVM accuracy:',sum(pred == data[,11]) / nrow(data),'\n')

cat('offset:',b(model),'\n')
cat('error',error(model),'\n')
kernelf(model)

```

##Kernal Selection

Checking different kernals and their affect on prediction accuracy - selected polydot for final model 
```{r trying all kernals}
kernals <- c('rbfdot','polydot','vanilladot','tanhdot','laplacedot','besseldot','anovadot','splinedot','stringdot')

for(kernal in kernals){
model <- ksvm(x, y, type = "C-svc", kernal = kernal, C=100, scaled = TRUE, cross = 5)
pred <- predict(model,data[,1:10])
cat('\n',kernal,'pred: ', sum(pred == data[,11]) / nrow(data))
}
```


##Paramater Hypertuning

Utilized the MLR package for parameter tuning, selected C=2.73e+06 for highest prediction accuracy
```{r, message=FALSE, warning=FALSE}
#Trying mlr package for parameter hypertuning 

trainTask <- makeClassifTask(data = data, target = 'R1')
trainTask
learner <- makeLearner("classif.ksvm")

ksvm <- makeLearner("classif.ksvm", predict.type = "response")
getParamSet("classif.ksvm")

set_cv <- makeResampleDesc("CV",iters = 3L)
pssvm <- makeParamSet(
  makeNumericParam("C", lower = -10, upper = 10, trafo = function(x) 10^x),
  makeNumericParam("sigma", lower = -10, upper = 10, trafo = function(x) 10^x)
)


ctrl = makeTuneControlRandom(maxit = 200L)

res <- tuneParams(ksvm, task = trainTask, resampling = set_cv, par.set = pssvm, control = ctrl)

t.svm <- setHyperPars(ksvm, par.vals = res$x)

par.svm <- train(ksvm, trainTask)
predict.svm <- predict(par.svm, trainTask)

res

```


##Question Number 3:  Training KKNN - Using Test, Train, And Validate data sets - Attempted Leave One Out Cross Validation however I could not get the correct results
```{r, eval=FALSE, message=FALSE, warning=FALSE, include=TRUE}
#Initial Model Creation
train.knn <- kknn(formula = formula(train$R1~.), train = train, test = test, k = 50, distance = 1, kernel = "optimal", scale=TRUE)

fit <- fitted(train.knn)

# table(test$R1, fit)

#Used this for optimal parameters
fit.train1 <- train.kknn(R1 ~ ., train, kmax = 99,
	kernel = "optimal", distance = 1)

fit.train1$best.parameters

cat('KKNN accuracy:',sum(fit == test[,11]) / nrow(test),'\n')


#Attempt with Leave One Out Cross Validation 
result <- rep(0,nrow(data))

for (i in nrow(data)){
   knn <- kknn(R1~., data[-i,], data[i,], k=100, scale=TRUE)
   
   result[i] <- round(fitted(knn),0)
}


```

